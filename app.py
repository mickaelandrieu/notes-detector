# -*- coding: utf-8 -*-
"""La détection de faux billets

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DLmo8652jbrIo3uya_tV7xc5meVX2DMC

# Réalisation d'un système de détection de faux billets

## Import des données
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import plotly.express as px
import scipy as sp
from sklearn import preprocessing, decomposition
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
import scipy.stats as st
import seaborn as sns
import warnings

warnings.simplefilter("ignore", np.VisibleDeprecationWarning)
# %matplotlib inline

drive.mount('/content/drive')
# loading dataset
notes = pd.read_csv('/content/drive/MyDrive/Données/OC/P6/notes.csv')

notes

"""## Mission 0 : Description du DataSet

* Nettoyage des données (détection des misses, erreurs et outliers)
* Analyse univariée
* Analyse bivariée (recherche de corrélation)
"""

# Supprimer les lignes avec des valeurs nulles
notes = notes.dropna().reset_index(drop=True)
notes

# Nombre de True/False
true_notes = notes.groupby('is_genuine').get_group(True)
false_notes = notes.groupby('is_genuine').get_group(False)
print(notes.groupby('is_genuine').is_genuine.count())

"""Il y a 70 faux billets et 100 vrais billets."""

true_notes.mean()

false_notes.mean()

"""Il semblerait que les faux billets présentent :

* une propriété ``margin_low`` supérieure aux vrais billets
* une propriété ``length`` inférieure aux vrais billets

Les autres propriétés ne semblent pas significatives à première vue.
"""

properties = (column for column in notes.columns if column != 'is_genuine')
for note_property in properties:
  fig = px.box(notes, x='is_genuine', y=note_property, width=400, height=400,)
  fig.show(renderer="colab")

fig = px.box(notes, x='is_genuine', y='length', width=400, height=400)

fig.show(renderer="colab")

"""## Mission 1 : Analyse en Composante Principale (ACP)

* Analyse de l'éboulis des valeurs propres ;
* Représentation des variables par le cercle des corrélations ;
* Représentation des individus par les plans factoriels ;
* Analyse de la qualité de représentation et la contribution des individus.

Pour chacune de ces étapes, commentez les résultats obtenus. La variable donnant la nature Vrai/Faux du billet sera utilisée comme variable illustrative.

### Fonctions utiles au projet
"""

def display_circles(pcs, n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):
    for d1, d2 in axis_ranks: # On affiche les 3 premiers plans factoriels, donc les 6 premières composantes
        if d2 < n_comp:

            # initialisation de la figure
            fig, ax = plt.subplots(figsize=(7,6))

            # détermination des limites du graphique
            if lims is not None :
                xmin, xmax, ymin, ymax = lims
            elif pcs.shape[1] < 30 :
                xmin, xmax, ymin, ymax = -1, 1, -1, 1
            else :
                xmin, xmax, ymin, ymax = min(pcs[d1,:]), max(pcs[d1,:]), min(pcs[d2,:]), max(pcs[d2,:])

            # affichage des flèches
            # s'il y a plus de 30 flèches, on n'affiche pas le triangle à leur extrémité
            if pcs.shape[1] < 30 :
                plt.quiver(np.zeros(pcs.shape[1]), np.zeros(pcs.shape[1]),
                   pcs[d1,:], pcs[d2,:], 
                   angles='xy', scale_units='xy', scale=1, color="grey")
                # (voir la doc : https://matplotlib.org/api/_as_gen/matplotlib.pyplot.quiver.html)
            else:
                lines = [[[0,0],[x,y]] for x,y in pcs[[d1,d2]].T]
                ax.add_collection(LineCollection(lines, axes=ax, alpha=.1, color='black'))
            
            # affichage des noms des variables  
            if labels is not None:  
                for i,(x, y) in enumerate(pcs[[d1,d2]].T):
                    if x >= xmin and x <= xmax and y >= ymin and y <= ymax :
                        plt.text(x, y, labels[i], fontsize='14', ha='center', va='center', rotation=label_rotation, color="blue", alpha=0.5)
            
            # affichage du cercle
            circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')
            plt.gca().add_artist(circle)

            # définition des limites du graphique
            plt.xlim(xmin, xmax)
            plt.ylim(ymin, ymax)
        
            # affichage des lignes horizontales et verticales
            plt.plot([-1, 1], [0, 0], color='grey', ls='--')
            plt.plot([0, 0], [-1, 1], color='grey', ls='--')

            # nom des axes, avec le pourcentage d'inertie expliqué
            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))
            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))

            plt.title("Cercle des corrélations (F{} et F{})".format(d1+1, d2+1))
            plt.show(block=False)
        
def display_factorial_planes(X_projected, n_comp, pca, axis_ranks, labels=None, alpha=1, title='', illustrative_var=None, legend_labels=None):
    for d1,d2 in axis_ranks:
        if d2 < n_comp:
 
            # initialisation de la figure       
            fig = plt.figure(figsize=(7,6))
        
            # affichage des points
            if illustrative_var is None:
                plt.scatter(X_projected[:, d1], X_projected[:, d2], alpha=alpha)
            else:
                illustrative_var = np.array(illustrative_var)
                for value in np.unique(illustrative_var):
                    selected = np.where(illustrative_var == value)
                    plt.scatter(X_projected[selected, d1], X_projected[selected, d2], alpha=alpha, label=value)
                if legend_labels is None:
                  plt.legend()
                else:
                  plt.legend(legend_labels)

            # affichage des labels des points
            if labels is not None:
                for i,(x,y) in enumerate(X_projected[:,[d1,d2]]):
                    plt.text(x, y, labels[i],
                              fontsize='14', ha='center',va='center') 
                
            # détermination des limites du graphique
            boundary = np.max(np.abs(X_projected[:, [d1,d2]])) * 1.1
            plt.xlim([-boundary,boundary])
            plt.ylim([-boundary,boundary])
        
            # affichage des lignes horizontales et verticales
            plt.plot([-100, 100], [0, 0], color='grey', ls='--')
            plt.plot([0, 0], [-100, 100], color='grey', ls='--')

            # nom des axes, avec le pourcentage d'inertie expliqué
            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))
            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))

            plt.title("{} (sur F{} et F{})".format(title, d1+1, d2+1))
            plt.show(block=False)

def display_scree_plot(pca):
    scree = pca.explained_variance_ratio_*100
    plt.bar(np.arange(len(scree))+1, scree)
    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c="red",marker='o')
    plt.xlabel("rang de l'axe d'inertie")
    plt.ylabel("pourcentage d'inertie")
    plt.title("Eboulis des valeurs propres")
    plt.show(block=False)

def plot_dendrogram(Z, names, image_name):
    plt.figure(figsize=(10,25))
    plt.title('Hierarchical Clustering Dendrogram')
    plt.xlabel('distance')
    dendrogram(
        Z,
        labels = names,
        orientation = "left",
        leaf_font_size = 1,
        color_threshold = 5
    )
    plt.savefig(image_name, format='png', dpi=600)
    plt.show(block=False)

def display_roc(false_positive_rate, true_positive_rate, roc_auc):
  plt.figure(figsize=(10,10))
  plt.title('Courbe ROC (Receiver Operating Characteristic)')
  plt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)
  plt.legend(loc = 'lower right')
  plt.plot([0, 1], [0, 1],linestyle='--')
  plt.axis('tight')
  plt.ylabel('True Positive Rate')
  plt.xlabel('False Positive Rate')
  plt.show(block=False)

"""### Analyse des valeurs propres

"""

# préparation des données pour le clustering

notes_without_guenine = notes.drop(columns=['is_genuine'])
X = notes_without_guenine.values
names = notes_without_guenine.index

# Centrage et Réduction
std_scale = preprocessing.StandardScaler().fit(X)
X_scaled = std_scale.transform(X)

nb_components = 6

pca = decomposition.PCA(n_components=nb_components)
pca.fit(X_scaled)

# Construction de l'éboulis des valeurs propres
display_scree_plot(pca)

# Affichage du cercle des corrélations sur les 3 premiers plans factoriels
pcs = pca.components_
display_circles(pcs, nb_components, pca, [(0,1), (2,3), (4,5)], labels = np.array(notes_without_guenine.columns))

"""### Projection des individus (Vrais et Faux billets)"""

# Projection des individus
X_projected = pca.transform(X_scaled)
display_factorial_planes(X_projected, nb_components, pca, [(0,1)],illustrative_var=notes.is_genuine)
display_factorial_planes(X_projected, nb_components, pca, [(2,3)],illustrative_var=notes.is_genuine)
display_factorial_planes(X_projected, nb_components, pca, [(4,5)],illustrative_var=notes.is_genuine)

"""### Interprétation de l'ACP

*   Item 1
*   Item 2
*   Item 3

### Complétion du jeu de données avec les composantes F1, F2, F3 et F4
"""

components = pd.DataFrame(X_projected, columns=['F1', 'F2', 'F3', 'F4', 'F5', 'F6'])

notes_with_components = notes.merge(components, left_index=True, right_index=True)

notes_with_components.drop(columns=['F5', 'F6'], inplace=True)

notes_with_components

"""## Mission 2 : Classification

Appliquez un algorithme de classification, puis analysez le résultat obtenu.

Visualisez la partition obtenue dans le premier plan factoriel de l'ACP, puis analysez-la.

### Régression Logistique : premier essai et résultats
"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import roc_curve, auc

X_log = notes_with_components.drop(columns=['is_genuine'])
y = notes.is_genuine

# Create training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_log, notes.is_genuine, test_size = 0.33, random_state=42)

# Create the classifier: logreg
logreg = LogisticRegression(max_iter=400)

print(logreg.get_params)

# Fit the classifier to the training data
logreg.fit(X_train, y_train)

# Predict the labels of the test set: y_pred
y_pred = logreg.predict(X_test)

# Compute and print the confusion matrix and classification report
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

# On récupère la prédiction de la valeur positive
y_prob = logreg.predict_proba(X_test)[:,1] 

# On créé un vecteur de prédiction à partir du vecteur de probabilités
y_pred = np.where(y_prob > 0.5, 1, 0) 

false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(false_positive_rate, true_positive_rate)
print('Valeur de l\'aire sous la courbe: '+str(roc_auc))

display_roc(false_positive_rate, true_positive_rate, roc_auc);

"""### Amélioration du modèle

Nous pouvons essayer d'optimiser les paramètres passer à notre algorithme de Régression Logistique, à l'aide de la fonction `GridSearchCV` qui s'effectue en passant par une validation croisée :
"""

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

current_logreg = LogisticRegression(max_iter=400)
params = {'C': np.logspace(-3, 3, 7) , 'penalty':['l2'] }

improved_logreg = GridSearchCV(current_logreg, params, cv=10)
improved_logreg.fit(X_train, y_train)

print(improved_logreg.best_params_)

"""Nous avons maintenant les meilleurs paramètres à passer à l'algorithme de régression logistique, mais est-ce que les prédictions sont meilleures ?"""

# On récupère la prédiction de la valeur positive
y_prob_improved = improved_logreg.predict_proba(X_test)[:,1] 

# On créé un vecteur de prédiction à partir du vecteur de probabilités
y_pred_improved = np.where(y_prob_improved > 0.5, 1, 0) 

false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob_improved)
improved_roc_auc = auc(false_positive_rate, true_positive_rate)
print(confusion_matrix(y_test, y_pred_improved))
print(classification_report(y_test, y_pred_improved))

print('Valeur de l\'aire sous la courbe: '+str(improved_roc_auc))


display_roc(false_positive_rate, true_positive_rate, improved_roc_auc);

print(improved_roc_auc == roc_auc)

"""L'améliorations des paramètres de l'algorithme n'a pas amélioré la qualité des prédictions, probablement parce que l'échantillon d'entraînement est trop petit.

Mais nous avons déjà un modèle d'excellente qualité théorique.

## Mission 3 : Construction du détecteur de faux billets

Modélisez les données à l'aide d'une régression logistique.

Grâce à celle-ci, vous créerez un programme capable d'effectuer une prédiction sur un billet, c'est-à-dire de déterminer s'il s'agit d'un vrai ou d'un faux billet.

Pour chaque billet, votre algorithme de classification devra donner la probabilité que le billet soit vrai. Si cette probabilité est supérieure ou égale à 0.5, le billet sera considéré comme vrai. Dans le cas contraire, il sera considéré comme faux.
"""

def predict_note_is_genuine(note):
  prob = improved_logreg.predict_proba(note)

  is_genuine = prob > 0.5
  return {
      'is_genuine': is_genuine,
      'prob': prob
  }